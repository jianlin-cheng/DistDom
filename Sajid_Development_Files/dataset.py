# -*- coding: utf-8 -*-
"""Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qKQzCIgY9E4n9FRtKexmrssHkSbBNp87
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install biopython
import torch
import torch.utils.data as data
import torch.nn as nn
from torch.nn.utils.rnn import pad_sequence
import os
import glob
from PIL import Image
import numpy as np
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import pandas as pd
from torch.utils.data import Dataset, TensorDataset
from Bio import SeqIO
from torch.utils.data import random_split
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt
# %matplotlib inline





codes = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',
         'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']

# def show_matrix(m):
#     #display a matrix
#     cm = sns.light_palette("seagreen", as_cmap=True)
#     display(m.style.background_gradient(cmap=cm))

def one_hot_encode(seq):
    o = list(set(codes) - set(seq))
    s = pd.DataFrame(list(seq))
    x = pd.DataFrame(np.zeros((len(seq),len(o)),dtype=int),columns=o)
    a = s[0].str.get_dummies(sep=',')
    a = a.join(x)
    a = a.sort_index(axis=1)
    a = a.to_numpy()
    # show_matrix(a)
    # e = a.values.flatten()
    return a

class my_dataset(data.Dataset):
    def initialize(self, distance_map, fasta,labels):
        # assert os.path.isdir(root_path), '%s is not a valid directory' % root_path

        # List all JPEG images
        distance_maps_path = os.path.join(distance_map, '*.npy')
        fasta_path = os.path.join(fasta,'*.fasta')
        labels_path = os.path.join(labels,'*.pt')
        self.distance_maps = glob.glob(distance_maps_path)
        self.fastas = glob.glob(fasta_path)
        self.labels = glob.glob(labels_path)
        self.size = len(self.distance_maps)
        self.size_fasta = len(self.fastas)
        self.size_labels = len(self.labels)

        # Define a transform to be applied to each image
        # Here we resize the image to 224X224 and convert it to Tensor
        self.transform = transforms.Compose([ transforms.ToTensor()])

    def __getitem__(self, index):
        # Loads a single data point from the dataset
        # Supporting integer indexing in range from 0 to the size of the dataset (exclusive)

        path = self.distance_maps[index % self.size]
        path_fasta = self.fastas[index % self.size_fasta]
        path_labels = self.labels[index % self.size_labels]
        # label = int(((path.split('/')[-1]).split('.')[0])=='cat')   # Ectract label from the filename
        # img = Image.open(path).convert('RGB')                       # Load the image and convert to RGB
        dist = np.squeeze(np.load(path))
        with open(path_fasta) as handle:
          for record in SeqIO.parse(handle, "fasta"):
            one_hot_sequence = one_hot_encode(record.seq)
        # dist = np.moveaxis(dist,-1,0)
        # img = self.transform(img)                                   # Apply the defined transform
        dist = self.transform(dist)
        # print(len(one_hot_sequence))
        # one_hot_sequence = pad_sequence(one_hot_sequence)
        one_hot_sequence = self.transform(one_hot_sequence)

        ground_truth = torch.load(path_labels)
        return {'dist': dist, 'one_hot_sequence': one_hot_sequence, 'ground_truth': ground_truth}

    def __len__(self):
        # Provides the size of the dataset

        return self.size



###CUSTOM Tensor DATASET
class CustomTensorDataset(Dataset):
    """TensorDataset with support of transforms.
    """
    def __init__(self, tensors, transform=None):
        assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors)
        self.tensors = tensors
        self.transform = transform

    def __getitem__(self, index):
        dist = self.tensors[0][index]

        if self.transform:
            dist = self.transform(dist)

        one_hot_sequence = self.tensors[1][index]

        labels = self.tensors[2][index]

        return dist, one_hot_sequence, labels

    def __len__(self):
        return self.tensors[0].size(0)

path = '/content/drive/MyDrive/Dataset/distance_maps/Mini_Batch'
path_fasta = '/content/drive/MyDrive/Dataset/Fasta/Mini_Batch'
path_ground_truth = '/content/drive/MyDrive/Dataset/Labels/Mini_Batch'
dataset = my_dataset()
dataset.initialize(path, path_fasta, path_ground_truth)
print(dataset.__getitem__(1)['ground_truth'].size())



#max_len

max_len = 0
for i in range(0,dataset.__len__()):
  length = dataset.__getitem__(i)['dist'].size(-1)
  if (length > max_len):
    max_len = length
print(max_len)

###Padding One hot
one_hot_sequence_list = []

for i in range(0,dataset.__len__()):
  one_hot_sequence_list.append(dataset.__getitem__(i)['one_hot_sequence'].squeeze())
  # print(dist_list[i].size())
one_hot_tensors = pad_sequence(one_hot_sequence_list,batch_first=True)
# print(one_hot_sequence_list_padded.size())
# one_hot_tensors = torch.stack(one_hot_sequence_list_padded,dim=0)
# print(one_hot_sequence_list_padded[0].size())


###Padding dist map
dist_list = []
for i in range(0,dataset.__len__()):
  zeros = torch.zeros(10,max_len,max_len)
  source = dataset.__getitem__(i)['dist']
  source_length_last_dim = source.size(-1)
  zeros[:,:source_length_last_dim,:source_length_last_dim] = source
  dist_list.append(zeros)

# print(dist_list[0].size())
dist_tensors = torch.stack(dist_list,dim=0)

### Padding Labels
List_labels = []
for i in range(0,dataset.__len__()):
    List_labels.append(dataset.__getitem__(i)['ground_truth'])
Padded_labels = pad_sequence(List_labels,batch_first=True)

print(one_hot_tensors.size(), dist_tensors.size(), Padded_labels.size())

train_dataset_normal = CustomTensorDataset(tensors=(dist_tensors, one_hot_tensors, Padded_labels), transform=None)

train_set, validation_set = random_split(train_dataset_normal, [8, 2], generator=torch.Generator().manual_seed(42))





batchSize = 1
shuffle = True
nThreads = 4

# Create a dataloader
train_loader = torch.utils.data.DataLoader(train_set, batch_size=batchSize, shuffle=None, num_workers=nThreads)
validation_loader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=None, num_workers=nThreads)

# for i, data in enumerate(dataloader):
#     dist = data['dist']
#     seq = data['one_hot_sequence']
#     # print(dist.size())
#     print(seq.size())

for i, data in enumerate(train_loader):
  dist, seq, label = data
  print(dist.size(), seq.size(), label.size())

# 3x3 convolution
def conv3x3(in_channels, out_channels, stride=1):
    return nn.Conv2d(in_channels, out_channels, kernel_size=3, 
                     stride=stride, padding=1, bias=False)

def conv1x1(in_channels, out_channels, stride=1):
    return nn.Conv2d(in_channels, out_channels, kernel_size=1, 
                     stride=stride, padding=0, bias=False)


class ResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(ResidualBlock, self).__init__()
        self.conv1 = conv3x3(in_channels, out_channels, stride)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(out_channels, out_channels)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.downsample = downsample
        
    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        if self.downsample:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)
        return out


class Net(nn.Module):
    def __init__(self, blocks, block, in_channel, out_channel):
        super(Net, self).__init__()
        layer = []
        layer.append(block(in_channel,out_channel))
        for i in range(0,blocks):
          layer.append(block(out_channel,out_channel))
        self.network = nn.Sequential(*layer)
        self.conv1x1 = conv1x1(out_channel,1)
        self.maxpoolbyrow = nn.AdaptiveMaxPool2d(output_size=(50,50))
    def reinitialize_maxpool(self,x):
        self.maxpoolbyrow = nn.AdaptiveMaxPool2d(output_size=(x.size()[-1],50))
        

    def forward(self, x):
        out = self.network(x)
        # self.maxpoolbyrow = nn.AdaptiveMaxPool2d(output_size=(x.size()[-1],50))
        # self.reinitialize_maxpool(x)
        # out = self.maxpoolbyrow(out)
        out = F.adaptive_max_pool2d(out,output_size=(x.size()[-1],50))
        # out = self.conv1x1(out)
        out = out.view(batchSize,500,-1)
        return out


def conv3x3_1d(in_channels, out_channels, stride=1):
    return nn.Conv1d(in_channels, out_channels, kernel_size=3, 
                     stride=stride, padding=1, bias=False)


class ResidualBlock_1d(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(ResidualBlock_1d, self).__init__()
        self.conv1 = conv3x3_1d(in_channels, out_channels, stride)
        self.bn1 = nn.BatchNorm1d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3_1d(out_channels, out_channels)
        self.bn2 = nn.BatchNorm1d(out_channels)
        self.downsample = downsample
        
    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        if self.downsample:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)
        return out

class Bi_RNN(nn.Module):

    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=11, num_layers=2, rnn_type='LSTM'):
        super(Bi_RNN, self).__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.batch_size = batch_size
        self.num_layers = num_layers

        #Define the initial linear hidden layer
        self.init_linear = nn.Linear(self.input_dim, self.input_dim)

        # Define the LSTM layer
        self.lstm = eval('nn.' + rnn_type)(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, bidirectional=True)

        # Define the output layer
        self.linear = nn.Linear(self.hidden_dim * 2, output_dim)

    def init_hidden(self):
        # This is what we'll initialise our hidden state as
        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),
                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))

    def forward(self, input):
        #Forward pass through initial hidden layer
        linear_input = self.init_linear(input)

        # Forward pass through LSTM layer
        # shape of lstm_out: [batch_size, input_size ,hidden_dim]
        # shape of self.hidden: (a, b), where a and b both
        # have shape (batch_size, num_layers, hidden_dim).
        lstm_out, self.hidden = self.lstm(linear_input)

        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction
        y_pred = self.linear(lstm_out)
        return y_pred


class Net_1d(nn.Module):
    def __init__(self, blocks, block, in_channel, out_channel):
        super(Net_1d, self).__init__()
        layer = []
        layer.append(block(in_channel,out_channel))
        for i in range(0,blocks):
          layer.append(block(out_channel,out_channel))
        # layer.append(Bi_RNN(46,20,1,1))
        self.network = nn.Sequential(*layer)
        self.bislstm = Bi_RNN(20,20,batch_size=batchSize,output_dim=500)
        self.maxpoolbyrow = nn.AdaptiveMaxPool2d(output_size=(50,50))
    def reinitialize_maxpool(self,x):
        self.maxpoolbyrow = nn.AdaptiveMaxPool2d(output_size=(x.size()[-1],50))
        # self.BiLSTM = Bi_RNN(46,20,1,50)

    def forward(self, x):
        out = self.network(x)
        out = out.permute(0,2,1)
        out = self.bislstm(out)
        # self.maxpoolbyrow = nn.AdaptiveMaxPool2d(output_size=(x.size()[-1],50))
        # self.reinitialize_maxpool(x)
        # out = self.maxpoolbyrow(out)
        # out = F.adaptive_max_pool2d(out,output_size=(x.size()[-1],50))
        # out = self.BiLSTM(out)
        out = out.permute(0,2,1)
        return out


class Net_Final(nn.Module):
    def __init__(self, blocks,L):
        super(Net_Final, self).__init__()
        self.network_2d = Net(blocks, ResidualBlock, 10, 10)
        self.network_1d = Net_1d(blocks, ResidualBlock_1d, 20, 20)
        # self.attention = Attention(L)
        self.Transformer = nn.Transformer(L,nhead=1)

    def forward(self, x_2d, x_1d, tgt):
        out_2d = self.network_2d(x_2d)
        out_1d = self.network_1d(x_1d)
        # print(out_2d.size(),out_1d.size())
        # output, weights = self.attention(out_1d,out_2d)
        output = torch.cat((out_2d,out_1d),dim=1)
        # print(output.permute(1,0,2).size(),tgt.permute(1,0,2).size())
        output = self.Transformer(output.permute(1,0,2), tgt.permute(1,0,2))
        return output

Final_Network = Net_Final(blocks = 100, L= max_len).cuda()
tgt = torch.randn(batchSize,1,max_len).cuda()

criterion = nn.BCEWithLogitsLoss().cuda()
# optimizer = optim.Adam(Final_Network.parameters(),lr=0.001)
optimizer = optim.SGD(Final_Network.parameters(),lr=0.001,momentum=0.9)

training_loss_list = []
validation_loss_list = []

for epoch in range(0,100):
  Final_Network.train()
  running_loss = 0.0
  running_validation_loss = 0.0
  for i, data in enumerate(train_loader):
    dist, seq, label = data
    dist = dist.float().cuda()
    seq = seq.permute(0,2,1).float().cuda()
    label = torch.unsqueeze(label,1).float().cuda()
    # print(type(dist),type(seq),type(label))
    optimizer.zero_grad()
    output_final = Final_Network(dist,seq,tgt)
    loss = criterion(output_final.permute(1,0,2),label)
    running_loss += loss.item()
    loss.backward()
    optimizer.step()
    if (i+1)%len(train_loader)== 0:
      print("Epoch: {0} Loss: {1}".format(epoch+1,running_loss/len(train_loader)))
      training_loss_list.append(running_loss/len(train_loader))
  with torch.no_grad():
    for i,data in enumerate(validation_loader):
      dist, seq, label = data
      dist = dist.float().cuda()
      seq = seq.permute(0,2,1).float().cuda()
      label = torch.unsqueeze(label,1).float().cuda()
      output_final = Final_Network(dist,seq,tgt)
      loss = criterion(output_final.permute(1,0,2),label)
      running_validation_loss += loss.item()
      if (i+1)%len(validation_loader)== 0:
        print("Epoch: {0} Validation Loss: {1}".format(epoch+1,running_validation_loss/len(validation_loader)))
        validation_loss_list.append(running_validation_loss/len(validation_loader))

train_plot = plt.plot(training_loss_list,label='Training')
validation_plot = plt.plot(validation_loss_list,label='Validation')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(loc="upper right")
plt.show()